# Conclusion

This study systematically evaluated the diagnostic accuracy and hallucination behavior of the Gemini 2.0 Flash model across seven prompting strategies applied to a curated set of medical multiple-choice questions. The results clearly demonstrate that prompt design plays a pivotal role in shaping LLM performance, particularly in high-stakes domains such as clinical decision-making.

Among all strategies tested, **Instruction-Heavy** and **Few-Shot prompting** yielded the highest diagnostic accuracy, confirming that structured guidance and relevant examples significantly enhance the model’s reasoning reliability. Conversely, **Safety-Constrained prompting** produced the lowest hallucination rate, underscoring its effectiveness in reducing fabricated or unsafe outputs. **Self-Verification** emerged as a promising hybrid approach, achieving a favorable balance between accuracy and safety. Meanwhile, **Chain-of-Thought prompting**, though useful for interpretability, introduced more variability and occasional hallucinations.

These findings highlight a crucial insight: **no single prompting strategy is universally optimal**. Instead, the best choice depends on the intended clinical context—whether the priority is maximizing accuracy, minimizing hallucination risk, or improving answer stability. The reproducible evaluation framework developed in this work—including multi-API key rotation, self-consistency sampling, hallucination detection, and automated visualization—provides a solid foundation for future benchmarking and refinement of prompting methodologies.

Ultimately, this study demonstrates that even lightweight LLMs available under free-tier constraints can perform meaningfully in medical diagnostic tasks when supported by well-designed prompts. As LLMs continue to advance, careful prompt engineering will remain a core mechanism for ensuring safe, interpretable, and reliable behavior in medical applications. Future work should expand dataset size, explore cross-model comparisons, and develop automated strategies for optimizing prompts in clinically realistic settings.
